# 控制平面扩展

要扩展 Kubernetes 集群，首先要保证控制平面的稳定性和伸缩性。稳定性受您集群的版本、配置、规模、使用方式等因素影响。而伸缩能力则由 TKE 提供产品化能力，通过资源利用率自动完成控制面的水平扩容。

## 使用我们推荐的版本

使用推荐的集群版本并积极升级他们，能让您的集群更加安全和稳定。容器服务 TKE 也会定期发布并维护平台所支持的 TKE Kubernetes 版本，具体可参考 [TKE Kubernetes 版本维护机制](https://cloud.tencent.com/document/product/457/74736) 了解集群版本支持机制、发布日历和过期风险。

## 配置集群

容器服务 TKE 提供丰富的能力让您快速创建一个高可用 Kubernetes 集群，具体流程可以参照 [创建集群](https://cloud.tencent.com/document/product/457/32189)。其中集群规格、运行时和网络是您最需要关注的。

### 1. 必要的集群拆分

Kubernetes 架构存在性能瓶颈，超大的集群规模可能会影响集群的可用性和性能。在使用大规模集群前，您应该了解 Kubernetes 社区定义的 [thresholds 与 SLO](https://github.com/kubernetes/community/blob/master/sig-scalability/configs-and-limits/thresholds.md)，并根据你的业务进行集群拆分。

### 2. 集群规格

评估您的业务选择合适的控制面规格往往是非常困难的，TKE 结合海量运营经验使用节点数量简化评估过程，您首先应该参照 [集群规格配置](https://cloud.tencent.com/document/product/457/90035)，根据业务实际情况选择合适的集群规格，以免集群控制面组件负载过大导致集群不可用。建议保持自动升配打开，在面对集群压力增长的时候自动触发规格升配，并通过腾讯云可观测平台可以接受升配相关事件。

### 3. 运行时选择

从 1.24 版本开始容器运行时切换为 containerd 而不是 docker。containerd 具有调用链更短，组件更少，更稳定，占用节点资源更少等优势，成为了最优选择。但是在以下情况下，请选择 Docker 作为运行时组件：

- 如需使用 Docker in Docker
- 如需在 TKE 节点使用 `docker build`/`push`/`save`/`load` 等命令
- 如需调用 Docker API
- 如需使用 Docker Compose 或 Docker Swarm

### 4. 网络配置

VPC-CNI 模式作为 TKE 推荐网络模式，具有 IP 利用率高、转发性能强、支持固定 IP 等优势。但是如果您有分布式云场景，需要选择 Cilium-Overlay 网络模式。具体差异可以参考 [容器集群网络方案选型](https://cloud.tencent.com/document/product/457/50353)。Service 转发模式对稳定性要求极高且 Service 数量小于 2000 时，建议选择 iptables，其余场景建议首选 ipvs。

## 关注规模和限制

为保证集群的稳定性和各项性能，请关注下表列出的限制及对应的推荐解决方案。

## 控制工作负载和节点爆发

TKE 默认开启自动升配，控制平面将随着集群的增长而自动扩展，但是它的扩展速度有限制。为了避免在控制平面上达到 API 限制，应该控制扩展节奏。

### 1. 扩展节奏管理

#### a. 扩展峰值控制

您应该限制一次将集群大小增加两位数百分比的扩展峰值（例如，1000 个节点增加到 1100 个节点，或者同时增加 4000 到 4500 个 Pod）。

#### b. 扩展冷却时间

保持 5-10 分钟冷却周期，这样能够让扩展资源得到消化。

### 2. 水平扩展

#### a. 使用自定义指标

CPU 和内存可能无法准确预测您的应用程序限制，在 Kubernetes 水平容器自动扩缩器 (HPA) 中使用自定义指标（例如每秒请求数）可能是更好的扩展选项，具体参考 [在 TKE 上利用 HPA 实现业务的弹性伸缩](https://cloud.tencent.com/document/product/457/37384)。

## 安全的替换工作负载和节点

### 1. 替换长时间运行的实例

定期更换节点可以避免配置偏差和只有在延长正常运行时间后才会出现的问题（例如缓慢的内存泄漏），从而保持集群的健康。自动替换将为您提供良好的节点升级和安全补丁流程和实践。如果定期更换集群中的每个节点，那么维护单独的进程以进行持续维护所需的辛勤工作就会减少。

使用 Karpenter 的生存时间 (TTL) 设置在实例运行了指定时间后替换这些实例。自我管理的节点组可以使用该 `max-instance-lifetime` 设置自动循环节点。

### 2. 节点缩容优化

#### a. 配置 TKE 节点自动扩缩器参数

#### b. Karpenter 中使用配置器设置 `ttlSecondsAfterEmpty` 实现安全排水

## API 性能优化

### 1. 客户端优化

#### a. 大量重复调用

如果使用 kubectl 命令效率低下，可能会给 Kubernetes API 服务器增加额外的负载。你应该避免运行重复使用 kubectl 的脚本或自动化（例如在 for 循环中），或者在没有本地缓存的情况下运行命令。

#### b. 增长客户端缓存刷新时间

kubectl 具有客户端缓存，用于缓存来自集群的发现信息，以减少所需的 API 调用量。默认情况下，缓存处于启用状态，并且每 10 分钟刷新一次。您也可以设置更久的刷新时间。

#### c. 复用缓存目录

如果您从容器或没有客户端缓存的情况下运行 kubectl，则可能会遇到 API 限制问题。建议通过挂载来保留您的集群缓存 `--cache-dir`，以避免进行不必要的 API 调用。

#### d. 禁用 kubectl 压缩

在 kubeconfig 文件中禁用 kubectl 压缩可以降低 API 和客户端 CPU 的使用率。默认情况下，服务器将压缩发送到客户端的数据以优化网络带宽。这会增加每个请求在客户端和服务器上的 CPU 负载，如果您有足够的带宽，禁用压缩可以减少开销和延迟。要禁用压缩，你可以使用 `--disable-compression=true` 标志或在 kubeconfig 文件中设置 `disable-compression: true`。

#### e. 使用 Informer

构建控制器或者自动化时，通常需要从 Kubernetes 资源中获取数据，如果每次拉取数据会造成 API Server 负载过重。使用 client-go 中的 Informer 可以监听数据变化并缓存数据，通过查询缓存数据进一步减少负载。Informer 应该避免没有标签和字段选择器的情况下监听整个集群内的资源，不然会导致 API Server 从 Etcd 返回大量不必要的数据，然后客户端进行过滤，造成从客户端、服务端、存储层整个链路的高负载。

#### f. 使用分页拉取数据

**核心参数组合**:

- `limit=500`：单次请求最多返回 500 条记录
- `continue=<token>`：配合分页令牌实现连续分页

**典型请求示例**:

响应中包含 `continue` 字段时，表示还有后续数据需继续请求。

**性能敏感点**:

- 单次 `limit` 最大值建议不超过 1000（默认 500），过大可能导致 API 服务器内存压力
- 分页深度与延迟：连续分页请求会累积 ETCD 查询开销，建议通过 `resourceVersion` 参数控制数据版本

#### g. 拉取缓存数据

如果在没有及时性限制的场景，列出对象建议使用 [Kubernetes API Concepts](https://kubernetes.io/docs/reference/using-api/api-concepts/#the-resourceversion-parameter)。如果不带任何 `resourceVersion` 参数，您将收到最新的可用版本，该版本需要 etcd 读取，这是数据库中最昂贵和最慢的读取。注意使用 `resourceVersion` 不支持分页。

## 服务端过载保护

当集群业务规模庞大时，对控制面会造成巨大的压力，雪崩时甚至可能无法通过有效扩容来解决，必须要结合流控、熔断等方案对异常请求进行排队、限速，以保障控制面的稳定性。

TKE 针对不同 K8s 版本提供了不同的限速策略，同时也通过 etcd 过载保护、apiserver 胖瘦分离等一系列特性对控制面进行加固。

参考 [TKE 集群 APF Expensive List 限速和熔断最佳实践](../availability/apiserver-rate-limiting.md)

## 灾难恢复策略

在 Kubernetes 集群中，控制面是敏感数据的核心枢纽，承载着集群状态、配置等关键信息。腾讯云 TKE 托管集群通过提供备份中心、etcd 常态化备份、误删除保护等能力，为控制面数据安全提供基础保障。

参考 [TKE 控制面最佳实践](../availability/backup-and-recovery.md)

## 扩容控制平面

随着业务的增长，之前规划的规格无法满足需求。TKE 针对托管集群和独立集群都提供了扩容控制面能力。

### 1. 扩展托管集群

#### a. 手动调整集群规格

通过集群基本信息页 -- 集群信息 -- 集群规格，手动调整规格，参照 [集群规格配置](https://cloud.tencent.com/document/product/457/90035) 选择满足您现在需求的规格，注意虽然 TKE 使用节点数简化规格评估过程，但是如果您的集群存储大量资源的时候，您更应该关注指引中说明的资源数量限制。

#### b. 自动调整集群规格

通过集群基本信息页 -- 集群信息 -- 集群规格 -- 自动升配，开启自动升配能力。开启自动升配时，TKE 会根据集群节点和资源用量自动调整规格。升配后会增加集群管理费用，您需手动下调集群规格。计费标准请参考 [容器服务计费概述](https://cloud.tencent.com/document/product/457/68804)。建议开通事件总线，及时接收集群自动升配或因费用不足升配失败的通知，开通可前往 [腾讯云事件总线](https://console.cloud.tencent.com/eb)。

### 2. 扩展独立集群

#### a. 通过新建 Master 扩容

通过集群基本信息页 -- 节点管理 -- Master&Etcd -- 新建 Master，来扩容 master 节点。TKE 独立集群扩容考虑到客户可能调整控制面参数，所以新节点会使用随机已有 Master 作为基础 image、参数扩容新的 Master，请保证已有 Master 控制面配置一致。

!!! warning "注意"
    如果您已经对存量 Master 做了自定义配置修改，新增的 Master 可能会由于配置不一致而初始化失败。您可以自行移出初始化失败的 Master，但请尽量确保集群中 Master 数目 >= 3，以确保集群的稳定性。

## 总结

通过版本控制、资源规划、自动化扩缩容及 API 优化，可显著提升 TKE 集群控制平面的扩展性与稳定性。建议结合业务需求选择网络模式与服务类型，定期审计资源使用情况，并利用 TKE 提供的监控与备份工具构建高可用架构。具体实施细节可参考腾讯云官方文档与 Kubernetes 社区最佳实践 [SIG Scalability](https://github.com/kubernetes/community/tree/master/sig-scalability)。
